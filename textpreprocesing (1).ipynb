{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21078ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re #text cleaning (preprocessing)\n",
    "import nltk #natural language toolkit, used for preprocessing\n",
    "import string \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cec54055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Whole = pd.read_csv(\"D:/AI/twcs.csv\" , nrows=5000)\n",
    "df=df_Whole[[\"text\"]]\n",
    "df_Whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86993ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length_tweet = df['text'].str.len().plot.hist(color = 'blue' , figsize = (6,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fff3531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5000.000000\n",
       "mean      107.410600\n",
       "std        50.893906\n",
       "min         6.000000\n",
       "25%        72.000000\n",
       "50%       108.000000\n",
       "75%       134.000000\n",
       "max       387.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Whole['length'] = df['text'].str.len()\n",
    "df_Whole['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "099ced76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@marksandspencer @117241 @117244 @117242 @Tesco @sainsburys @117248 @AldiUK @117249 @Morrisons @117250 @117251 @117243 @117247 Imagine making your customers pay more than twice as much per pie for your top range and still only scoring a point higher than our basics. ;)\\n\\nJust you wait till our Deluxe mince pies get marked! And on that note, @117242 drop us a DM! https://t.co/8X2QAr23zN'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Whole[df_Whole['length']==387] ['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "329a6396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tweet_id     author_id  inbound                      created_at  \\\n",
      "0            1    sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
      "1            2        115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
      "2            3        115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
      "3            4    sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
      "4            5        115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
      "...        ...           ...      ...                             ...   \n",
      "4995      7627  hulu_support    False  Thu Nov 02 15:29:37 +0000 2017   \n",
      "4996      7628  hulu_support    False  Thu Nov 02 15:31:46 +0000 2017   \n",
      "4997      7626        117290     True  Mon Oct 30 02:13:57 +0000 2017   \n",
      "4998      7629  hulu_support    False  Tue Oct 31 23:40:03 +0000 2017   \n",
      "4999      7630        117291     True  Mon Oct 30 01:57:36 +0000 2017   \n",
      "\n",
      "                                                   text response_tweet_id  \\\n",
      "0     @115712 I understand. I would like to assist y...                 2   \n",
      "1         @sprintcare and how do you propose we do that               NaN   \n",
      "2     @sprintcare I have sent several private messag...                 1   \n",
      "3     @115712 Please send us a Private Message so th...                 3   \n",
      "4                                    @sprintcare I did.                 4   \n",
      "...                                                 ...               ...   \n",
      "4995  @117290 Hm, they should definitely resume if a...               NaN   \n",
      "4996  @117290 That's where they need to be on, so ch...               NaN   \n",
      "4997  @115940 Can you guys maybe like....FIX your st...              7624   \n",
      "4998  @117291 Hulu is only available in the U.S. rig...               NaN   \n",
      "4999  @115940 when will the platform available in la...              7629   \n",
      "\n",
      "      in_response_to_tweet_id  length  \n",
      "0                         3.0     121  \n",
      "1                         1.0      45  \n",
      "2                         4.0      82  \n",
      "3                         5.0     124  \n",
      "4                         6.0      18  \n",
      "...                       ...     ...  \n",
      "4995                   7625.0     131  \n",
      "4996                   7625.0     147  \n",
      "4997                      NaN     140  \n",
      "4998                   7630.0     134  \n",
      "4999                      NaN      89  \n",
      "\n",
      "[5000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_Whole)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66bd408a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>@sprintcare i have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>@115712 please send us a private message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>@sprintcare i did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_lower  \n",
       "0  @115712 i understand. i would like to assist y...  \n",
       "1      @sprintcare and how do you propose we do that  \n",
       "2  @sprintcare i have sent several private messag...  \n",
       "3  @115712 please send us a private message so th...  \n",
       "4                                 @sprintcare i did.  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.......................changing the casing of the words................................\n",
    "df = df_Whole.iloc[:,4:5]\n",
    "df[\"text\"] = df['text'].astype(str)\n",
    "df[\"text_lower\"] = df[\"text\"].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d5b9b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>115712 I understand I would like to assist you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>sprintcare I have sent several private message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>115712 Please send us a Private Message so tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>sprintcare I did</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_punct  \n",
       "0  115712 I understand I would like to assist you...  \n",
       "1       sprintcare and how do you propose we do that  \n",
       "2  sprintcare I have sent several private message...  \n",
       "3  115712 Please send us a Private Message so tha...  \n",
       "4                                   sprintcare I did  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuations\n",
    "df.drop([\"text_lower\"], axis=1, inplace=True)\n",
    "puncremove = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    return text.translate(str.maketrans('','',puncremove))\n",
    "df[\"text_punct\"] = df[\"text\"].apply(lambda text: remove_punctuation(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cca6c9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hima\\anaconda3\\lib\\site-packages (3.6.3)\n",
      "Collecting nltk\n",
      "  Using cached nltk-3.6.5-py3-none-any.whl (1.5 MB)\n",
      "Requirement already satisfied: joblib in c:\\users\\hima\\anaconda3\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hima\\anaconda3\\lib\\site-packages (from nltk) (2021.10.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hima\\anaconda3\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: click in c:\\users\\hima\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Installing collected packages: nltk\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.6.3\n",
      "    Uninstalling nltk-3.6.3:\n",
      "      Successfully uninstalled nltk-3.6.3\n",
      "Successfully installed nltk-3.6.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be6cc5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re #text cleaning (preprocessing)\n",
    "import nltk #natural language toolkit, used for preprocessing\n",
    "import string \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54580fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'both', 'she', 'where', 'there', 're', 'o', 'if', 'them', 'we', 'of', 'about', 'over', 'hadn', \"hadn't\", 'for', 'has', 'll', 'couldn', 'under', 'not', 'him', 'm', 'which', 'you', 'will', 'aren', 'before', \"you're\", 've', 'in', 'as', \"haven't\", 'out', \"you'll\", 'do', 'such', 'haven', 'does', 'down', 'a', 'doesn', 'can', 'then', 'ourselves', 'wouldn', 'my', 'against', \"wouldn't\", 'than', \"didn't\", 'own', 'so', 'nor', 'this', \"shan't\", 'don', 'again', 'because', 'me', 'above', 'myself', 'by', 'through', 'few', \"won't\", 'her', 'mustn', 'our', 'to', 'and', 'hers', 'what', 'while', \"should've\", 'further', 'am', 'their', 'once', 'whom', 'only', 'was', 'here', 'wasn', \"weren't\", 'at', 'why', 'very', 'these', 'd', 'who', 'just', 'until', 'too', 'they', 'yourselves', \"mustn't\", \"isn't\", 'now', 'some', \"you've\", 'he', 'himself', \"needn't\", 'won', \"you'd\", 'your', 'when', 'should', 'each', 'how', \"aren't\", 'being', 'it', 'having', 'its', 'theirs', 'an', 'any', 'into', 'i', 'is', 'ain', \"don't\", \"it's\", 'shan', 'yours', 'yourself', 'all', 'on', \"mightn't\", 'hasn', 'shouldn', 'or', 'isn', 'same', 'after', 'doing', 'itself', 'were', 'ma', 'been', 'with', \"doesn't\", 'ours', 'but', \"she's\", 'that', 'more', 'his', 'didn', \"shouldn't\", 'needn', 'other', 's', 'most', 'the', 'y', 'from', 'are', \"hasn't\", 'did', 'herself', 'up', \"that'll\", \"couldn't\", 'those', 'themselves', 'mightn', 'weren', \"wasn't\", 'be', 'no', 't', 'during', 'between', 'have', 'had', 'off', 'below'}\n"
     ]
    }
   ],
   "source": [
    "stops = set(stopwords.words('english'))\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cffb3103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_punct</th>\n",
       "      <th>text_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>115712 I understand I would like to assist you...</td>\n",
       "      <td>115712 I understand I would like assist We wou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>sprintcare I have sent several private message...</td>\n",
       "      <td>sprintcare I sent several private messages one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>115712 Please send us a Private Message so tha...</td>\n",
       "      <td>115712 Please send us Private Message assist J...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>sprintcare I did</td>\n",
       "      <td>sprintcare I</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_punct  \\\n",
       "0  115712 I understand I would like to assist you...   \n",
       "1       sprintcare and how do you propose we do that   \n",
       "2  sprintcare I have sent several private message...   \n",
       "3  115712 Please send us a Private Message so tha...   \n",
       "4                                   sprintcare I did   \n",
       "\n",
       "                                           text_stop  \n",
       "0  115712 I understand I would like assist We wou...  \n",
       "1                                 sprintcare propose  \n",
       "2  sprintcare I sent several private messages one...  \n",
       "3  115712 Please send us Private Message assist J...  \n",
       "4                                       sprintcare I  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df[\"text_stop\"] = df[\"text_punct\"].apply(lambda text: remove_stopwords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc37d129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 1437),\n",
       " ('us', 752),\n",
       " ('DM', 514),\n",
       " ('help', 479),\n",
       " ('Please', 376),\n",
       " ('We', 338),\n",
       " ('Hi', 293),\n",
       " ('Thanks', 287),\n",
       " ('get', 279),\n",
       " ('please', 247)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for text in df[\"text_stop\"].values:\n",
    "    for word in text.split():\n",
    "        cnt[word] += 1\n",
    "        \n",
    "cnt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36ff794d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_punct</th>\n",
       "      <th>text_stop</th>\n",
       "      <th>text_stopfreq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>115712 I understand I would like to assist you...</td>\n",
       "      <td>115712 I understand I would like assist We wou...</td>\n",
       "      <td>115712 understand would like assist would need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>sprintcare propose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>sprintcare I have sent several private message...</td>\n",
       "      <td>sprintcare I sent several private messages one...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>115712 Please send us a Private Message so tha...</td>\n",
       "      <td>115712 Please send us Private Message assist J...</td>\n",
       "      <td>115712 send Private Message assist Just click ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>sprintcare I did</td>\n",
       "      <td>sprintcare I</td>\n",
       "      <td>sprintcare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                          text_punct  \\\n",
       "0  115712 I understand I would like to assist you...   \n",
       "1       sprintcare and how do you propose we do that   \n",
       "2  sprintcare I have sent several private message...   \n",
       "3  115712 Please send us a Private Message so tha...   \n",
       "4                                   sprintcare I did   \n",
       "\n",
       "                                           text_stop  \\\n",
       "0  115712 I understand I would like assist We wou...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare I sent several private messages one...   \n",
       "3  115712 Please send us Private Message assist J...   \n",
       "4                                       sprintcare I   \n",
       "\n",
       "                                       text_stopfreq  \n",
       "0  115712 understand would like assist would need...  \n",
       "1                                 sprintcare propose  \n",
       "2  sprintcare sent several private messages one r...  \n",
       "3  115712 send Private Message assist Just click ...  \n",
       "4                                         sprintcare  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqwords = set([w for (w, wc) in cnt.most_common(10)])\n",
    "def remove_freqwords(text):\n",
    "    \"\"\"custom function to remove the frequent words\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in freqwords])\n",
    "\n",
    "df[\"text_stopfreq\"] = df[\"text_stop\"].apply(lambda text: remove_freqwords(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b96a65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([\"text_punct\", \"text_stop\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab1b06d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stopfreq</th>\n",
       "      <th>text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>115712 understand would like assist would need...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>@sprintcar and how do you propos we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "      <td>@sprintcar i have sent sever privat messag and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>115712 send Private Message assist Just click ...</td>\n",
       "      <td>@115712 pleas send us a privat messag so that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>@sprintcar i did.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@115712 Can you please send us a private messa...</td>\n",
       "      <td>115712 Can send private message gain details a...</td>\n",
       "      <td>@115712 can you pleas send us a privat message...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@sprintcare is the worst customer service</td>\n",
       "      <td>sprintcare worst customer service</td>\n",
       "      <td>@sprintcar is the worst custom servic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@115713 This is saddening to hear. Please shoo...</td>\n",
       "      <td>115713 This saddening hear shoot look KC</td>\n",
       "      <td>@115713 thi is sadden to hear. pleas shoot us ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@sprintcare You gonna magically change your co...</td>\n",
       "      <td>sprintcare You gonna magically change connecti...</td>\n",
       "      <td>@sprintcar you gonna magic chang your connect ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@115713 We understand your concerns and we'd l...</td>\n",
       "      <td>115713 understand concerns wed like send Direc...</td>\n",
       "      <td>@115713 we understand your concern and we'd li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "5  @115712 Can you please send us a private messa...   \n",
       "6          @sprintcare is the worst customer service   \n",
       "7  @115713 This is saddening to hear. Please shoo...   \n",
       "8  @sprintcare You gonna magically change your co...   \n",
       "9  @115713 We understand your concerns and we'd l...   \n",
       "\n",
       "                                       text_stopfreq  \\\n",
       "0  115712 understand would like assist would need...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare sent several private messages one r...   \n",
       "3  115712 send Private Message assist Just click ...   \n",
       "4                                         sprintcare   \n",
       "5  115712 Can send private message gain details a...   \n",
       "6                  sprintcare worst customer service   \n",
       "7           115713 This saddening hear shoot look KC   \n",
       "8  sprintcare You gonna magically change connecti...   \n",
       "9  115713 understand concerns wed like send Direc...   \n",
       "\n",
       "                                        text_stemmed  \n",
       "0  @115712 i understand. i would like to assist y...  \n",
       "1        @sprintcar and how do you propos we do that  \n",
       "2  @sprintcar i have sent sever privat messag and...  \n",
       "3  @115712 pleas send us a privat messag so that ...  \n",
       "4                                  @sprintcar i did.  \n",
       "5  @115712 can you pleas send us a privat message...  \n",
       "6              @sprintcar is the worst custom servic  \n",
       "7  @115713 thi is sadden to hear. pleas shoot us ...  \n",
       "8  @sprintcar you gonna magic chang your connect ...  \n",
       "9  @115713 we understand your concern and we'd li...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stemming(playing-play)\n",
    "stemmer = PorterStemmer()\n",
    "def stem_words(text):\n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "df[\"text_stemmed\"] = df[\"text\"].apply(lambda text: stem_words(text))\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c3b5cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "SnowballStemmer.languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e20fadfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stopfreq</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>115712 understand would like assist would need...</td>\n",
       "      <td>@115712 i understand. i would like to assist y...</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "      <td>@sprintcar and how do you propos we do that</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>sprintcare sent several private messages one r...</td>\n",
       "      <td>@sprintcar i have sent sever privat messag and...</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>115712 send Private Message assist Just click ...</td>\n",
       "      <td>@115712 pleas send us a privat messag so that ...</td>\n",
       "      <td>@115712 Please send u a Private Message so tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>@sprintcar i did.</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                       text_stopfreq  \\\n",
       "0  115712 understand would like assist would need...   \n",
       "1                                 sprintcare propose   \n",
       "2  sprintcare sent several private messages one r...   \n",
       "3  115712 send Private Message assist Just click ...   \n",
       "4                                         sprintcare   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0  @115712 i understand. i would like to assist y...   \n",
       "1        @sprintcar and how do you propos we do that   \n",
       "2  @sprintcar i have sent sever privat messag and...   \n",
       "3  @115712 pleas send us a privat messag so that ...   \n",
       "4                                  @sprintcar i did.   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  @115712 I understand. I would like to assist y...  \n",
       "1      @sprintcare and how do you propose we do that  \n",
       "2  @sprintcare I have sent several private messag...  \n",
       "3  @115712 Please send u a Private Message so tha...  \n",
       "4                                 @sprintcare I did.  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lemminizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "df[\"text_lemmatized\"] = df[\"text\"].apply(lambda text: lemmatize_words(text))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6eced1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sleeping'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"sleeping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7102164e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sleep'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"sleeping\",\"v\") # v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4a6f0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Word is : stripes\n",
      "Lemma result for verb :  strip\n",
      "Lemma result for noun :  stripe\n"
     ]
    }
   ],
   "source": [
    "print(\"The Word is : stripes\")\n",
    "print(\"Lemma result for verb : \",lemmatizer.lemmatize(\"stripes\", 'v'))\n",
    "print(\"Lemma result for noun : \",lemmatizer.lemmatize(\"stripes\", 'n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "466d97a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73b26bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\tb\n",
      "c\td\n"
     ]
    }
   ],
   "source": [
    "s = 'a\\tb\\nc\\td'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8f1317a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\\tb\\nc\\td\n"
     ]
    }
   ],
   "source": [
    "s = r'a\\tb\\nc\\td'\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aae02271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is my website,  check it out'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removal url\n",
    "text1 = \"This is my website, https://www.abc.com, check it out\"\n",
    "remove_urls(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "233b0965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Want to learn more. Checkout  for additional information'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Want to learn more. Checkout www.h2o.ai for additional information\"\n",
    "remove_urls(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e874ab1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re  # used for preprocessing\n",
    "import nltk  # Natural Language Toolkit, used for preprocessing\n",
    "import string #used for preprocessing\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "09ef96d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_whole = pd.read_csv(\"D:/AI/twcs.csv\", nrows=5000)\n",
    "df = df_whole[[\"text\"]]\n",
    "df_whole.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b20d4c8",
   "metadata": {},
   "source": [
    "D:/AI/twcs.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c95c39d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @115712 I understand. I would like to assist y...\n",
       "1      @sprintcare and how do you propose we do that\n",
       "2  @sprintcare I have sent several private messag...\n",
       "3  @115712 Please send us a Private Message so th...\n",
       "4                                 @sprintcare I did."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_whole.iloc[:,4:5]\n",
    "df[\"text\"] = df[\"text\"].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e42b536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all urls\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "# make all text lowercase\n",
    "def text_lowercase(text):\n",
    "    return text.lower()\n",
    "# remove numbers\n",
    "def remove_numbers(text):\n",
    "    result = re.sub(r'\\d+', '', text)\n",
    "    return result\n",
    "# remove punctuation\n",
    "def remove_punctuation(text):\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    return text.translate(translator)\n",
    "# tokenize\n",
    "def tokenize(text):\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "# remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    text = [i for i in text if not i in stop_words]\n",
    "    return text\n",
    "# lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(text):\n",
    "    text = [lemmatizer.lemmatize(token) for token in text]\n",
    "    return text\n",
    "\n",
    "def preprocessing(text):\n",
    "    text = text_lowercase(text)\n",
    "    text = remove_urls(text)\n",
    "    text = remove_numbers(text)\n",
    "    text = remove_punctuation(text)\n",
    "    text = tokenize(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = lemmatize(text)\n",
    "    text = ' '.join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20116fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_text_train = [] # our preprocessed text column\n",
    "for text_data in df['text']:\n",
    "    pp_text_data = preprocessing(text_data)\n",
    "    pp_text_train.append(pp_text_data)\n",
    "df['pp_text'] = pp_text_train # add the preprocessed text as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59e5bebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pp_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>understand would like assist would need get pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>sprintcare propose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>sprintcare sent several private message one re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>please send u private message assist click  m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>sprintcare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @115712 I understand. I would like to assist y...   \n",
       "1      @sprintcare and how do you propose we do that   \n",
       "2  @sprintcare I have sent several private messag...   \n",
       "3  @115712 Please send us a Private Message so th...   \n",
       "4                                 @sprintcare I did.   \n",
       "\n",
       "                                             pp_text  \n",
       "0  understand would like assist would need get pr...  \n",
       "1                                 sprintcare propose  \n",
       "2  sprintcare sent several private message one re...  \n",
       "3  please send u private message assist click  m...  \n",
       "4                                         sprintcare  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fff7550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text_data = list(df['pp_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2edf1cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf=TfidfVectorizer()\n",
    "\n",
    "# the vectorizer must be fit onto the entire corpus\n",
    "fitted_vectorizer = tf.fit(final_text_data)\n",
    "\n",
    "transform_all = fitted_vectorizer.transform(df['pp_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbb8f3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 6592)\t0.4454853089146968\n",
      "  (0, 6190)\t0.3034434132572768\n",
      "  (0, 5195)\t0.39652227962666964\n",
      "  (0, 4538)\t0.3569872924294605\n",
      "  (0, 3919)\t0.211805085603221\n",
      "  (0, 3433)\t0.2494122396698877\n",
      "  (0, 3418)\t0.20346740590382362\n",
      "  (0, 2468)\t0.19122283290246225\n",
      "  (0, 428)\t0.4896550547298487\n",
      "  (1, 5529)\t0.5809623692215399\n",
      "  (1, 4581)\t0.8139304181246056\n",
      "  (2, 6292)\t0.4460026583311189\n",
      "  (2, 5529)\t0.3454828856031298\n",
      "  (2, 5260)\t0.39051486925059314\n",
      "  (2, 5228)\t0.2852223952742473\n",
      "  (2, 4934)\t0.40152195029994797\n",
      "  (2, 4538)\t0.39051486925059314\n",
      "  (2, 4106)\t0.244352191309585\n",
      "  (2, 3700)\t0.27283656933931216\n",
      "  (3, 5997)\t0.3463374899646776\n",
      "  (3, 5221)\t0.22529209687753776\n",
      "  (3, 4560)\t0.40364811725929683\n",
      "  (3, 4538)\t0.3863660407684735\n",
      "  (3, 4399)\t0.16782732825684352\n",
      "  (3, 3700)\t0.5398759093336265\n",
      "  :\t:\n",
      "  (4997, 5944)\t0.19135392350771327\n",
      "  (4997, 5631)\t0.3170425915581468\n",
      "  (4997, 4106)\t0.19837926308508985\n",
      "  (4997, 3644)\t0.28824725303020676\n",
      "  (4997, 3492)\t0.37490173420019673\n",
      "  (4997, 3419)\t0.3929577418697719\n",
      "  (4997, 3322)\t0.25430794148437047\n",
      "  (4997, 2593)\t0.2333779305791527\n",
      "  (4997, 2005)\t0.3063032606997819\n",
      "  (4997, 910)\t0.37490173420019673\n",
      "  (4998, 6478)\t0.2082204574455405\n",
      "  (4998, 5692)\t0.2547821295760423\n",
      "  (4998, 5273)\t0.28583928884252746\n",
      "  (4998, 5244)\t0.20938533774074033\n",
      "  (4998, 5006)\t0.2636312476511054\n",
      "  (4998, 4074)\t0.39885413109826995\n",
      "  (4998, 3002)\t0.38965836509631707\n",
      "  (4998, 2814)\t0.3638938148886732\n",
      "  (4998, 497)\t0.270267574253898\n",
      "  (4998, 368)\t0.42461868130591396\n",
      "  (4999, 5493)\t0.45429525857518444\n",
      "  (4999, 4385)\t0.4242568607192531\n",
      "  (4999, 3327)\t0.5188976424045938\n",
      "  (4999, 497)\t0.31509981185650404\n",
      "  (4999, 368)\t0.4950548246848025\n"
     ]
    }
   ],
   "source": [
    "print(transform_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948ad71e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4072efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db9d742",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
